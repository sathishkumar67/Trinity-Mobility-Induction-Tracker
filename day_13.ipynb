{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers torch\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab4d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1\",\n",
    "                            trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0479a5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 768)\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Deep learning models require large datasets.\",\n",
    "    \"Neural networks work well with lots of data.\",\n",
    "    \"I like eating pizza.\"\n",
    "]\n",
    "\n",
    "embeddings = model.encode(\n",
    "    texts,\n",
    "    normalize_embeddings=True  \n",
    ")\n",
    "\n",
    "print(embeddings.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e294790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000002  0.62945104 0.24597904]\n",
      " [0.62945104 0.9999998  0.32259136]\n",
      " [0.24597904 0.32259136 1.0000002 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5731a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.657 → Neural networks need large datasets to perform well.\n",
      "0.254 → Pizza is my favorite food.\n",
      "0.445 → Transformers are used in modern NLP models.\n"
     ]
    }
   ],
   "source": [
    "query = \"How do neural networks learn from data?\"\n",
    "documents = [\n",
    "    \"Neural networks need large datasets to perform well.\",\n",
    "    \"Pizza is my favorite food.\",\n",
    "    \"Transformers are used in modern NLP models.\"\n",
    "]\n",
    "\n",
    "query_embedding = model.encode(query, normalize_embeddings=True)\n",
    "doc_embeddings = model.encode(documents, normalize_embeddings=True)\n",
    "\n",
    "scores = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "\n",
    "for doc, score in zip(documents, scores):\n",
    "    print(f\"{score:.3f} → {doc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663db882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"BAAI/bge-large-en-v1.5\")\n",
    "documents = [\n",
    "    \"Neural networks require large datasets.\",\n",
    "    \"Transformers are widely used in NLP.\",\n",
    "    \"Pizza is a popular Italian food.\"\n",
    "]\n",
    "\n",
    "doc_embeddings = model.encode(\n",
    "    [\"Represent this document for retrieval: \" + doc for doc in documents],\n",
    "    normalize_embeddings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd24cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do neural networks learn?\"\n",
    "\n",
    "query_embedding = model.encode(\n",
    "    \"Represent this query for retrieval: \" + query,\n",
    "    normalize_embeddings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89f62297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.817 → Neural networks require large datasets.\n",
      "0.702 → Transformers are widely used in NLP.\n",
      "0.456 → Pizza is a popular Italian food.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "scores = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "\n",
    "for doc, score in zip(documents, scores):\n",
    "    print(f\"{score:.3f} → {doc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "query = \"How does machine learning work?\"\n",
    "\n",
    "documents = [\n",
    "    \"Machine learning models learn from data.\",      # English\n",
    "    \"ಯಂತ್ರ ಕಲಿಕೆ ಡೇಟಾದಿಂದ ಕಲಿಯುತ್ತದೆ.\",             # Kannada\n",
    "    \"மெஷின் லெர்னிங் தரவிலிருந்து கற்றுக்கொள்கிறது\"  # Tamil\n",
    "]\n",
    "\n",
    "query_emb = model.encode(\n",
    "    \"Represent this query for retrieval: \" + query,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "doc_embs = model.encode(\n",
    "    [\"Represent this document for retrieval: \" + d for d in documents],\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "scores = cosine_similarity([query_emb], doc_embs)[0]\n",
    "\n",
    "for doc, score in zip(documents, scores):\n",
    "    print(f\"{score:.3f} → {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f2eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "sentences = [\n",
    "    \"Deep learning models require large datasets.\",\n",
    "    \"Neural networks learn from data.\",\n",
    "    \"I love eating pizza.\"\n",
    "]\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity(embeddings)\n",
    "\n",
    "print(similarity)\n",
    "\n",
    "embeddings = model.encode(\n",
    "    sentences,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "print(embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e39549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "train_examples = [\n",
    "    InputExample(\n",
    "        texts=[\"What is machine learning?\", \"Machine learning is a field of AI\"],\n",
    "        label=1.0\n",
    "    ),\n",
    "    InputExample(\n",
    "        texts=[\"I love pizza\", \"Neural networks are powerful\"],\n",
    "        label=0.0\n",
    "    )\n",
    "]\n",
    "from sentence_transformers import SentenceTransformer, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_examples,\n",
    "    shuffle=True,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=1,\n",
    "    warmup_steps=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
