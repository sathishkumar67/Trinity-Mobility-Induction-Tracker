{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89d6827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://192.168.1.120:11434\"\n",
    "MODEL_NAME = \"llama3.1:8b\"\n",
    "\n",
    "query = \"What is the capital of France?\"\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=MODEL_NAME,\n",
    "    base_url=OLLAMA_BASE_URL,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "response = llm.invoke(query)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13261a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Answer the following question clearly:\\n\\n{question}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde82ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1bd66b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "\n",
    "result = chain.invoke({\n",
    "    \"question\": \"What is the capital of France?\"\n",
    "})\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a4c16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableSequence chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ChatPromptTemplate chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StrOutputParser chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"**Entropy: A Simple Explanation**\\n\\nImagine you have a clean, tidy room. Everything is organized, and nothing is out of place. This represents **low entropy**.\\n\\nNow, imagine that someone throws a big party in your house. Guests come and go, food gets spilled, trash is generated, and the room becomes messy. This represents **high entropy**.\\n\\nIn simple terms, **entropy** is a measure of how much disorder or randomness there is in a system. The more disorganized something is, the higher its entropy.\\n\\nHere are some examples to illustrate this concept:\\n\\n* A neat and tidy garden has low entropy.\\n* A garden with weeds growing everywhere has high entropy.\\n* A perfectly folded piece of paper has low entropy.\\n* A crumpled up piece of paper has high entropy.\\n\\nIn everyday life, entropy increases over time. Things tend to become more disorganized and chaotic as they interact with their environment. For example:\\n\\n* Your tidy room becomes messy if you don't clean it regularly.\\n* A new bike gets scratched and dented over time if not properly maintained.\\n\\nEntropy is a fundamental concept in physics and chemistry that helps us understand the natural world around us. It's a reminder that things tend to become more disordered and random as they interact with their environment.\\n\\nI hope this explanation helps!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.callbacks import StdOutCallbackHandler  # â† new location\n",
    "\n",
    "handler = StdOutCallbackHandler()\n",
    "\n",
    "chain.invoke(\n",
    "    {\"question\": \"Explain entropy in simple terms\"},\n",
    "    config={\"callbacks\": [handler]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a8e8311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={} response_metadata={'model': 'llama3.1:8b', 'created_at': '2026-01-30T06:00:49.2092021Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2920359700, 'load_duration': 2650983800, 'prompt_eval_count': 163, 'prompt_eval_duration': 31655600, 'eval_count': 22, 'eval_duration': 207371600, 'logprobs': None, 'model_name': 'llama3.1:8b', 'model_provider': 'ollama'} id='lc_run--019c0d7d-5f92-7831-baba-2d3b886e8a80-0' tool_calls=[{'name': 'add', 'args': {'a': 12, 'b': 30}, 'id': '6751d2a1-f6e9-420d-a222-cf9e3073e27c', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 163, 'output_tokens': 22, 'total_tokens': 185}\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers\"\"\"\n",
    "    return a + b\n",
    "llm_with_tools = llm.bind_tools([add])\n",
    "response = llm_with_tools.invoke(\n",
    "    \"What is 12 plus 30?\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016147ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Trinity-Mobility-Induction-Tracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
